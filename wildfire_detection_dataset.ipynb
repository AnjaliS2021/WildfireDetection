{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnjaliS2021/WildfireDetection/blob/main/wildfire_detection_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ###### Licensed to the Apache Software Foundation (ASF), Version 2.0 (the \"License\")\n",
        "\n",
        "# Licensed to the Apache Software Foundation (ASF) under one\n",
        "# or more contributor license agreements. See the NOTICE file\n",
        "# distributed with this work for additional information\n",
        "# regarding copyright ownership. The ASF licenses this file\n",
        "# to you under the Apache License, Version 2.0 (the\n",
        "# \"License\"); you may not use this file except in compliance\n",
        "# with the License. You may obtain a copy of the License at\n",
        "#\n",
        "#   http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing,\n",
        "# software distributed under the License is distributed on an\n",
        "# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
        "# KIND, either express or implied. See the License for the\n",
        "# specific language governing permissions and limitations\n",
        "# under the License."
      ],
      "metadata": {
        "cellView": "form",
        "id": "xCRnNNaiFNFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "Purpose of this colab is to curate satellite imagery based tensorflow dataset for ML model based wildfire detection.\n",
        "\n",
        "Steps are:\n",
        "* University of Maryland catalogs â€œMonthly Fire Location Productâ€. Download the list for the months and years of interest.\n",
        "* Google Earth Engine hosts satelellite imagery. Download the MODIS satellite imageries for the dates and locations of interest.\n",
        "* Specifically, download MOD14A1 V6.1 imagery. It provides daily fire mask composites at 1km resolution derived from the MODIS 4-micrometer and 11-micrometer radiances.\n",
        "* Transform the satellite imagery into tensorflow example dataset.\n",
        "* Save the dataset files into google drive.\n",
        "\n",
        "References:\n",
        "* https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD14A1#description\n",
        "* https://developers.google.com/earth-engine/guides/machine-learning\n",
        "* https://github.com/GoogleCloudPlatform/python-docs-samples/blob/main/people-and-planet-ai/land-cover-classification/README.ipynb\n"
      ],
      "metadata": {
        "id": "0gyRAGiOzSsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installs\n",
        "!pip install --quiet earthengine-api\n",
        "!pip install --quiet apache-beam\n",
        "!pip install --quiet apache-beam[interactive]\n",
        "!pip install --quiet pysftp"
      ],
      "metadata": {
        "id": "OIdChZMncckO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "from datetime import datetime\n",
        "from datetime import date as datetime_date\n",
        "from google.api_core import exceptions, retry\n",
        "from google.colab import auth\n",
        "from numpy.lib.recfunctions import structured_to_unstructured\n",
        "\n",
        "import apache_beam as beam\n",
        "import ee\n",
        "import google.auth\n",
        "import gzip\n",
        "import io\n",
        "import numpy as np\n",
        "import os\n",
        "import pysftp\n",
        "import requests\n",
        "import tensorflow as tf\n",
        "import shutil\n",
        "import time"
      ],
      "metadata": {
        "id": "ovXi8tffW9y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVz5zhvZ1mM3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce72f807-84e2-4870-8d20-4be2e99d6b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "#@title Earth Engine Authentication\n",
        "# Please fill in google earth engine project id.\n",
        "project = \"ee-wildfire-detection-ml\"  # @param {type:\"string\"}\n",
        "assert project, \"Please provide a Google Cloud project ID\"\n",
        "# Set GOOGLE_CLOUD_PROJECT for google.auth.default().\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = project\n",
        "\n",
        "auth.authenticate_user()\n",
        "# Set the gcloud project for other gcloud commands.\n",
        "!gcloud config set project {project}\n",
        "\n",
        "credentials, _ = google.auth.default()\n",
        "ee.Initialize(\n",
        "    credentials.with_quota_project(None),\n",
        "    project=project,\n",
        "    opt_url=\"https://earthengine-highvolume.googleapis.com\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Google Drive Mount\n",
        "# Save dataset on persistent storage to avoid deletion after colab restart.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "wildfire_drive_path = '/content/drive/MyDrive/wildfire_detection'\n",
        "os.makedirs(wildfire_drive_path, exist_ok=True)\n",
        "print(os.listdir(wildfire_drive_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbekcFDMuf_g",
        "outputId": "cbd91b69-2bea-4191-a7ff-796d6ef61b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Wildfire Identification"
      ],
      "metadata": {
        "id": "Br1PXmCznvGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Univ of Maryland\n",
        "class Maryland:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.max_wildfires = 100\n",
        "    self.build_paths()\n",
        "    self.build_directories(cleanup=False)\n",
        "    self.build_dates()\n",
        "    self.build_filenames()\n",
        "    # Checks google drive for existing files, only downloads files that don't\n",
        "    # exist already.\n",
        "    self.download_files()\n",
        "    self.build_wildfires()\n",
        "\n",
        "  def __str__(self):\n",
        "    messages = [\n",
        "      'University of Maryland MODIS Monthly Fire Location Product',\n",
        "      f'Num dates: {len(self.dates)}',\n",
        "      f'Num files: {len(self.filenames)}',\n",
        "      f'Num wildfires: {len(self.wildfires)}',\n",
        "      f'all files: {self.all_files}',\n",
        "    ]\n",
        "    return '\\n'.join(messages)\n",
        "\n",
        "  def build_paths(self):\n",
        "    self.base_directory = wildfire_drive_path\n",
        "    self.source_directory = 'data/MODIS/C6/MCD14ML'\n",
        "    self.destination_directory = os.path.join(\n",
        "        self.base_directory, 'maryland_files')\n",
        "\n",
        "  def build_directories(self, cleanup=False):\n",
        "    if cleanup:\n",
        "      shutil.rmtree(self.destination_directory, ignore_errors=True)\n",
        "    os.makedirs(self.destination_directory, exist_ok=True)\n",
        "\n",
        "  def build_dates(self):\n",
        "    self.dates = []\n",
        "    years = [2023, ]\n",
        "    months = range(1, 13)\n",
        "    for year in years:\n",
        "      for month in months:\n",
        "        date = datetime_date(year, month, 1)\n",
        "        date_str = date.strftime('%Y%m')\n",
        "        self.dates.append(date_str)\n",
        "    print(self.dates)\n",
        "\n",
        "  def build_filenames(self):\n",
        "    self.filenames = []\n",
        "    for date in self.dates:\n",
        "      filename = f'MCD14ML.{date}.006.03.txt.gz'\n",
        "      self.filenames.append(filename)\n",
        "\n",
        "  def get_pending_download_filenames(self):\n",
        "    print(f'Lookup existing files in: {self.destination_directory}')\n",
        "    existing_files = os.listdir()\n",
        "    print(f'Num existing files: {len(existing_files)}')\n",
        "    self.all_files = existing_files\n",
        "    filenames = []\n",
        "    for filename in self.filenames:\n",
        "      if filename not in existing_files:\n",
        "        filenames.append(filename)\n",
        "    print(f'Num files to download: {len(filenames)}')\n",
        "    return filenames\n",
        "\n",
        "  def download_files(self):\n",
        "    hostname = 'fuoco.geog.umd.edu'\n",
        "    username = 'fire'\n",
        "    password = 'burnt'\n",
        "    with pysftp.cd(self.destination_directory):\n",
        "      filenames = self.get_pending_download_filenames()\n",
        "      if not filenames:\n",
        "        return\n",
        "      cnopts = pysftp.CnOpts()\n",
        "      cnopts.hostkeys = None\n",
        "      with pysftp.Connection(hostname, username=username,\n",
        "                             password=password, cnopts=cnopts) as sftp:\n",
        "        with sftp.cd(self.source_directory):\n",
        "          for filename in self.filenames:\n",
        "            try:\n",
        "              sftp.get(filename)\n",
        "            except Exception as e:\n",
        "              print(filename)\n",
        "              print(e)\n",
        "      self.all_files = os.listdir()\n",
        "\n",
        "  def build_wildfires(self):\n",
        "    self.wildfires = []\n",
        "    for filename in self.filenames:\n",
        "      lines = self.read_destination_file(filename)\n",
        "      wildfires = self.build_wildfires_from_lines(filename, lines)\n",
        "      self.wildfires.extend(wildfires)\n",
        "    if self.max_wildfires > 0:\n",
        "      self.wildfires = self.wildfires[:self.max_wildfires]\n",
        "    if self.wildfires:\n",
        "      print(self.wildfires[0])\n",
        "\n",
        "  def build_wildfires_from_lines(self, filename, lines):\n",
        "    wildfires = []\n",
        "    indexes = None\n",
        "    header_length = 0\n",
        "    for line in lines:\n",
        "      if indexes is None: # Header line.\n",
        "        indexes = self.get_indexes(line)\n",
        "        if not indexes:\n",
        "          print('error: indexes are empty.')\n",
        "          break\n",
        "        header_length = len(line)\n",
        "        continue\n",
        "      if len(line) < header_length:\n",
        "        print(f'error: expected {header_length} entries. invalid line {line}')\n",
        "        break\n",
        "      wildfire = self.get_wildfire(filename, indexes, line)\n",
        "      wildfires.append(wildfire)\n",
        "    return wildfires\n",
        "\n",
        "  def get_indexes(self, line):\n",
        "    names = ['YYYYMMDD', 'lon', 'lat', 'FRP', 'conf', 'type']\n",
        "    indexes = {}\n",
        "    for i, word in enumerate(line):\n",
        "      if word in names:\n",
        "        indexes[word] = i\n",
        "    for name in names:\n",
        "      if indexes.get(name) is None:\n",
        "        print(f'error: {name} does not exist.')\n",
        "        return None\n",
        "    return indexes\n",
        "\n",
        "  def get_wildfire(self, filename, indexes, line):\n",
        "    wildfire = {'filename': filename,}\n",
        "    float_names = ['lon', 'lat', 'FRP', 'conf']\n",
        "    int_names = ['type']\n",
        "    for name, i in indexes.items():\n",
        "      value = line[i]\n",
        "      if name in float_names:\n",
        "        value = float(value)\n",
        "      if name in int_names:\n",
        "        value = int(value)\n",
        "      wildfire[name] = value\n",
        "    start_date = datetime.strptime(wildfire['YYYYMMDD'], '%Y%m%d')\n",
        "    wildfire['start'] = start_date.strftime('%Y-%m-%d')\n",
        "    return wildfire\n",
        "\n",
        "  def read_destination_file(self, filename):\n",
        "    lines = []\n",
        "    with pysftp.cd(self.destination_directory):\n",
        "      with gzip.open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "          line = line.decode(encoding='utf-8', errors='strict')\n",
        "          words = line.rstrip().split(' ')\n",
        "          non_empty_words = []\n",
        "          for word in words:\n",
        "            if len(word) > 0:\n",
        "              non_empty_words.append(word)\n",
        "          lines.append(non_empty_words)\n",
        "    return lines\n",
        "\n",
        "\n",
        "maryland = Maryland()\n",
        "print(maryland)"
      ],
      "metadata": {
        "id": "9dfeEtYOhSYI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a08b165e-ea61-4f1c-d85c-3eef197d8c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['202301', '202302', '202303', '202304', '202305', '202306', '202307', '202308', '202309', '202310', '202311', '202312']\n",
            "Lookup existing files in: /content/drive/MyDrive/wildfire_detection/maryland_files\n",
            "Num existing files: 0\n",
            "Num files to download: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pysftp/__init__.py:61: UserWarning: Failed to load HostKeys from /root/.ssh/known_hosts.  You will need to explicitly load HostKeys (cnopts.hostkeys.load(filename)) or disableHostKey checking (cnopts.hostkeys = None).\n",
            "  warnings.warn(wmsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCD14ML.202302.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "MCD14ML.202303.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "MCD14ML.202304.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "MCD14ML.202305.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "MCD14ML.202306.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "MCD14ML.202307.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "MCD14ML.202308.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "MCD14ML.202309.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "MCD14ML.202310.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "MCD14ML.202311.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "MCD14ML.202312.006.03.txt.gz\n",
            "[Errno 2] No such file\n",
            "{'filename': 'MCD14ML.202301.006.03.txt.gz', 'YYYYMMDD': '20230101', 'lat': -13.3373, 'lon': -44.1169, 'FRP': 7.0, 'conf': 54.0, 'type': 0, 'start': '2023-01-01'}\n",
            "University of Maryland MODIS Monthly Fire Location Product\n",
            "Num dates: 12\n",
            "Num files: 12\n",
            "Num wildfires: 100\n",
            "all files: ['MCD14ML.202301.006.03.txt.gz', 'MCD14ML.202302.006.03.txt.gz', 'MCD14ML.202303.006.03.txt.gz', 'MCD14ML.202304.006.03.txt.gz', 'MCD14ML.202305.006.03.txt.gz', 'MCD14ML.202306.006.03.txt.gz', 'MCD14ML.202307.006.03.txt.gz', 'MCD14ML.202308.006.03.txt.gz', 'MCD14ML.202309.006.03.txt.gz', 'MCD14ML.202310.006.03.txt.gz', 'MCD14ML.202311.006.03.txt.gz', 'MCD14ML.202312.006.03.txt.gz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ›° Earth Engine Satellite\n",
        "class Satellite:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.maryland = maryland\n",
        "    self.name = 'MODIS/061/MOD14A1'\n",
        "    self.bands = ['MaxFRP', 'FireMask', 'QA']\n",
        "    self.band_max_values = [6000, 9, 7]\n",
        "    self.low_confidence_fire_mask = 7\n",
        "    self.nominal_confidence_fire_mask = 8\n",
        "    self.high_confidence_fire_mask = 9\n",
        "    self.scale = 1000  # resolution in meters.\n",
        "    # NOTE: pixel_size=16, bands=3 means (16, 16, 3) image dimension.\n",
        "    self.pixel_size = 16\n",
        "    self.build_wildfires()\n",
        "    self.build_images()\n",
        "\n",
        "  def __str__(self):\n",
        "    messages = [\n",
        "      f'Satellite: {self.name}',\n",
        "      f'Bands: {self.bands}',\n",
        "      f'Wildfires: {len(self.wildfires)}',\n",
        "    ]\n",
        "    return '\\n'.join(messages)\n",
        "\n",
        "  def build_wildfires(self):\n",
        "    self.wildfires = self.maryland.wildfires\n",
        "    for wildfire in self.wildfires:\n",
        "      wildfire['name'] = wildfire['filename']\n",
        "      start_ee_date = ee.Date(wildfire['start'])\n",
        "      end_ee_date = start_ee_date.advance(1, 'day')\n",
        "      wildfire['date_range'] = ee.DateRange(start_ee_date, end_ee_date)\n",
        "\n",
        "  def build_images(self):\n",
        "    for wildfire in self.wildfires:\n",
        "      self.build_image(wildfire)\n",
        "\n",
        "  def build_image(self, wildfire):\n",
        "    area_of_interest = self.get_area_of_interest(wildfire)\n",
        "    image_collection = (\n",
        "        ee.ImageCollection(self.name)\n",
        "        .filterDate(wildfire['date_range'])\n",
        "        .filterBounds(area_of_interest)\n",
        "        .select(self.bands)\n",
        "    )\n",
        "    image = image_collection.max().clip(area_of_interest)\n",
        "    wildfire['image'] = image\n",
        "\n",
        "  def get_area_of_interest(self, wildfire):\n",
        "    lonlat = self.get_location(wildfire)\n",
        "    point = ee.Geometry.Point(lonlat)\n",
        "    num_pixels = self.pixel_size  # rectangle image = (num_pixel, num_pixels)\n",
        "    meters_per_pixel = 1000  # satellite resolution.\n",
        "    radius_meters = meters_per_pixel * num_pixels / 2\n",
        "    circular_area = point.buffer(radius_meters, 1)\n",
        "    rectangular_area = circular_area.bounds(1)\n",
        "    return rectangular_area\n",
        "\n",
        "  def get_location(self, wildfire):\n",
        "    return wildfire['lon'], wildfire['lat']\n",
        "\n",
        "  def get_band_index(self, name):\n",
        "    for i, band in enumerate(self.bands):\n",
        "      if name == band:\n",
        "        return i\n",
        "    return None\n",
        "\n",
        "  def download_wildfire_with_retry(self, wildfire, retries=3):\n",
        "    timeout = 2  # sec.\n",
        "    for i in range(retries):\n",
        "      try:\n",
        "        image_np = self.download_wildfire(wildfire)\n",
        "        if image_np is not None:\n",
        "          return image_np\n",
        "      except:\n",
        "        print(f'Retry {self.debug_wildfire(wildfire)}. sleep {timeout} sec.')\n",
        "        time.sleep(timeout)\n",
        "    return None\n",
        "\n",
        "  def download_wildfire(self, wildfire):\n",
        "    image = wildfire['image']\n",
        "    area_of_interest = self.get_area_of_interest(wildfire)\n",
        "    image_np = self.download_image(image, area_of_interest)\n",
        "    if image_np is not None:\n",
        "      image_np = structured_to_unstructured(image_np)\n",
        "    return image_np\n",
        "\n",
        "  def download_image(self, image, area_of_interest):\n",
        "    # image dimension: (pixel_size, pixel_size, num_bands).\n",
        "    num_pixels = self.pixel_size\n",
        "    params = {\n",
        "      'bands': self.bands,\n",
        "      \"region\": area_of_interest,\n",
        "      \"dimensions\": [num_pixels, num_pixels],\n",
        "      \"format\": \"NPY\",\n",
        "    }\n",
        "    url = image.getDownloadURL(params)\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 429:\n",
        "      raise exceptions.TooManyRequests(response.text)\n",
        "    if response.ok:\n",
        "      return np.load(io.BytesIO(response.content), allow_pickle=True)\n",
        "    return None\n",
        "\n",
        "  def debug_wildfire(self, wildfire):\n",
        "    short = {}\n",
        "    for key in ['lon', 'lat', 'start', 'name']:\n",
        "      short[key] = wildfire.get(key, 'n/a')\n",
        "    return short\n",
        "\n",
        "\n",
        "satellite = Satellite()\n",
        "print(satellite)"
      ],
      "metadata": {
        "id": "WQj0vJtS1VKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c9e916-c2b6-4649-e5e1-ca26f68018ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Satellite: MODIS/061/MOD14A1\n",
            "Bands: ['MaxFRP', 'FireMask', 'QA']\n",
            "Wildfires: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ—„ Dataset Download\n",
        "\n"
      ],
      "metadata": {
        "id": "bl0hrMIsrSyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ“‘ Build Dataset\n",
        "class DatasetBuilder():\n",
        "\n",
        "  def __init__(self):\n",
        "    self.satellite = satellite\n",
        "    self.build_wildfires()\n",
        "    # Divide wildfires into small groups to avoid colab timeout during download.\n",
        "    self.build_group_wildfires()\n",
        "    self.build_paths()\n",
        "    self.create_directories(cleanup=False)\n",
        "    # It checks the drive directory first and already downloaded groups are\n",
        "    # pruned from the download list.\n",
        "    self.build_pending_group_downloads()\n",
        "\n",
        "  def __str__(self):\n",
        "    messages = [\n",
        "      f'DatasetBuilder num Wildfires: {len(self.wildfires)}',\n",
        "      f'Num train wildfires: {len(self.train_wildfires)}',\n",
        "      f'Num test wildfires: {len(self.test_wildfires)}',\n",
        "      f'Num group train wildfires: {len(self.group_train_wildfires)}',\n",
        "      f'Num group test wildfires: {len(self.group_test_wildfires)}',\n",
        "      f'Train dataset path: {self.train_path}',\n",
        "      f'Test dataset path: {self.test_path}',\n",
        "    ]\n",
        "    return '\\n'.join(messages)\n",
        "\n",
        "  def build_wildfires(self):\n",
        "    self.wildfires = self.satellite.wildfires\n",
        "    self.split_wildfires()\n",
        "\n",
        "  def split_wildfires(self):\n",
        "    self.train_wildfires = []\n",
        "    self.test_wildfires = []\n",
        "    train_test_max_mods = 5\n",
        "    train_max_mods = 4  # total:train:test = 5:4:1.\n",
        "    for i, wildfire in enumerate(self.wildfires):\n",
        "      if i % train_test_max_mods < train_max_mods:\n",
        "        self.train_wildfires.append(wildfire)\n",
        "      else:\n",
        "        self.test_wildfires.append(wildfire)\n",
        "    # The test set should not be empty, add at least one entry.\n",
        "    if not self.test_wildfires and self.train_wildfires:\n",
        "      self.test_wildfires.append(self.train_wildfires[0])\n",
        "\n",
        "  def build_group_wildfires(self):\n",
        "    # small groups so that beam could download files without timeout.\n",
        "    self.group_train_wildfires = self.group_wildfires(self.train_wildfires)\n",
        "    self.group_test_wildfires = self.group_wildfires(self.test_wildfires)\n",
        "    print(f'groups: {self.group_train_wildfires.keys()}')\n",
        "\n",
        "  def group_wildfires(self, wildfires):\n",
        "    group_size = 10\n",
        "    groups = {}\n",
        "    for i, wildfire in enumerate(wildfires):\n",
        "      group_id = int(i / group_size)\n",
        "      group_dir = f'{group_id:05}'\n",
        "      if group_dir not in groups:\n",
        "        groups[group_dir] = []\n",
        "      groups[group_dir].append(wildfire)\n",
        "    return groups\n",
        "\n",
        "  def build_paths(self):\n",
        "    self.base_directory = wildfire_drive_path\n",
        "    self.dataset_directory = 'dataset'\n",
        "    self.dataset_path = os.path.join(\n",
        "      self.base_directory, self.dataset_directory)\n",
        "    self.train_path = os.path.join(self.dataset_path, 'train')\n",
        "    self.test_path = os.path.join(self.dataset_path, 'test')\n",
        "\n",
        "  def build_pending_group_downloads(self):\n",
        "    self.group_train_downloads = self.group_downloads(\n",
        "        self.train_path, self.group_train_wildfires)\n",
        "    self.group_test_downloads = self.group_downloads(\n",
        "        self.test_path, self.group_test_wildfires)\n",
        "\n",
        "  def group_downloads(self, dataset_path, group_wildfires):\n",
        "    downloads = []\n",
        "    print(f'Lookup existing groups in: {dataset_path}')\n",
        "    with pysftp.cd(dataset_path):\n",
        "      existing_groups = os.listdir()\n",
        "      print(f'Num existing groups: {len(existing_groups)}')\n",
        "      for group_id in group_wildfires.keys():\n",
        "        if group_id not in existing_groups:\n",
        "          downloads.append(group_id)\n",
        "    print(f'Num groups to download: {len(downloads)}')\n",
        "    return downloads\n",
        "\n",
        "  def create_directories(self, cleanup=False):\n",
        "    if cleanup:\n",
        "      shutil.rmtree(self.train_path, ignore_errors=True)\n",
        "      shutil.rmtree(self.test_path, ignore_errors=True)\n",
        "    os.makedirs(self.dataset_path, exist_ok=True)\n",
        "    os.makedirs(self.train_path, exist_ok=True)\n",
        "    os.makedirs(self.test_path, exist_ok=True)\n",
        "\n",
        "  def download_wildfires(self):\n",
        "    self.build_pending_group_downloads()\n",
        "    for group_id in self.group_train_downloads:\n",
        "      wildfires = self.group_train_wildfires[group_id]\n",
        "      dataset_path = self.train_path\n",
        "      self.download_group_wildfires(dataset_path, group_id, wildfires)\n",
        "    for group_id in self.group_test_downloads:\n",
        "      wildfires = self.group_test_wildfires[group_id]\n",
        "      dataset_path = self.test_path\n",
        "      self.download_group_wildfires(dataset_path, group_id, wildfires)\n",
        "\n",
        "  def download_group_wildfires(self, dataset_path, group_id, wildfires):\n",
        "    download_path = os.path.join(dataset_path, group_id, 'part')\n",
        "    print(f'Download {download_path}')\n",
        "    with beam.Pipeline() as pipeline:\n",
        "      (\n",
        "        pipeline\n",
        "        | 'List wildfires' >> beam.Create(wildfires)\n",
        "        | 'Serialize examples' >> beam.FlatMap(\n",
        "              self.flatmap_serialized_tf_example)\n",
        "        | 'Write TFRecords' >> beam.io.WriteToTFRecord(\n",
        "              download_path, file_name_suffix='.tfrecord.gz')\n",
        "      )\n",
        "\n",
        "  def flatmap_serialized_tf_example(self, wildfire):\n",
        "    example_bytes = self.get_serialized_tf_example(wildfire)\n",
        "    if example_bytes is None:\n",
        "      return []\n",
        "    return [example_bytes]\n",
        "\n",
        "  def get_serialized_tf_example(self, wildfire):\n",
        "    input_np, label_np = self.get_input_and_label(wildfire)\n",
        "    if input_np is None:\n",
        "      return None\n",
        "    example_bytes = self.serialize(wildfire, input_np, label_np)\n",
        "    return example_bytes\n",
        "\n",
        "  def get_input_and_label(self, wildfire):\n",
        "    image_np = self.satellite.download_wildfire_with_retry(wildfire)\n",
        "    if image_np is None:\n",
        "      return None, None\n",
        "    # MaxFRP and QA bands are part of the input.\n",
        "    input_np = self.get_input(image_np)\n",
        "    # FireMask band is the label.\n",
        "    label_np = self.get_label(image_np)\n",
        "    return input_np, label_np\n",
        "\n",
        "  def get_input(self, image_np):\n",
        "    input_np = image_np.copy()\n",
        "    fire_mask_index = self.satellite.get_band_index('FireMask')\n",
        "    input_np[:, :, fire_mask_index] = 0\n",
        "    return input_np\n",
        "\n",
        "  def get_label(self, image_np):\n",
        "    # (16, 16, 3) shape pixel image will return (16, 16, 1) shape label.\n",
        "    shape = list(image_np.shape)\n",
        "    shape[-1] = 1\n",
        "    label_np = np.ndarray(shape, int)\n",
        "    label_np.fill(0)\n",
        "    fire_mask_index = self.satellite.get_band_index('FireMask')\n",
        "    label_np[:, :, 0] = image_np[:, :, fire_mask_index]\n",
        "    label_np = self.clear_non_fire_labels(label_np)\n",
        "    return label_np\n",
        "\n",
        "  def clear_non_fire_labels(self, label_np):\n",
        "    # Fire values in the label are kept as-is, others are replaced with 0.\n",
        "    min_fire_label = self.satellite.low_confidence_fire_mask\n",
        "    masked_np = np.ma.masked_less(label_np, min_fire_label)\n",
        "    max_fire_label = self.satellite.high_confidence_fire_mask\n",
        "    masked_np = np.ma.masked_greater(masked_np, max_fire_label)\n",
        "    cleared_np = masked_np.filled(0)\n",
        "    return cleared_np\n",
        "\n",
        "  def serialize(self, wildfire, input_np, label_np):\n",
        "    input_bl = tf.train.BytesList(\n",
        "        value=[tf.io.serialize_tensor(input_np).numpy()])\n",
        "    label_bl = tf.train.BytesList(\n",
        "        value=[tf.io.serialize_tensor(label_np).numpy()])\n",
        "    features = {\n",
        "      'inputs':  tf.train.Feature(bytes_list=input_bl),\n",
        "      'labels':  tf.train.Feature(bytes_list=label_bl),\n",
        "    }\n",
        "    example = tf.train.Example(features=tf.train.Features(feature=features))\n",
        "    return example.SerializeToString()\n",
        "\n",
        "\n",
        "dataset_builder = DatasetBuilder()\n",
        "print(dataset_builder)"
      ],
      "metadata": {
        "id": "hzx5lNZLiCjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d5d913-1f82-43f1-c345-639099dc4187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "groups: dict_keys(['00000', '00001', '00002', '00003', '00004', '00005', '00006', '00007'])\n",
            "Lookup existing groups in: /content/drive/MyDrive/wildfire_detection/dataset/train\n",
            "Num existing groups: 0\n",
            "Num groups to download: 8\n",
            "Lookup existing groups in: /content/drive/MyDrive/wildfire_detection/dataset/test\n",
            "Num existing groups: 0\n",
            "Num groups to download: 2\n",
            "DatasetBuilder num Wildfires: 100\n",
            "Num train wildfires: 80\n",
            "Num test wildfires: 20\n",
            "Num group train wildfires: 8\n",
            "Num group test wildfires: 2\n",
            "Train dataset path: /content/drive/MyDrive/wildfire_detection/dataset/train\n",
            "Test dataset path: /content/drive/MyDrive/wildfire_detection/dataset/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ðŸ—ƒ Beam up\n",
        "dataset_builder.download_wildfires()"
      ],
      "metadata": {
        "id": "3wzC594wr75G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee50aa87-d441-464b-d001-ce05ae48b4ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lookup existing groups in: /content/drive/MyDrive/wildfire_detection/dataset/train\n",
            "Num existing groups: 8\n",
            "Num groups to download: 0\n",
            "Lookup existing groups in: /content/drive/MyDrive/wildfire_detection/dataset/test\n",
            "Num existing groups: 2\n",
            "Num groups to download: 0\n"
          ]
        }
      ]
    }
  ]
}